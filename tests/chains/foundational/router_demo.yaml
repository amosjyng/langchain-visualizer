interactions:
- request:
    body: ''
    headers:
      host:
      - 127.0.0.1:8935
    method: GET
    uri: http://127.0.0.1:8935/ping
  response:
    content: ought-ice says pong
    headers:
      cache-control:
      - no-transform
      content-length:
      - '19'
      content-type:
      - text/plain; charset=utf-8
      date:
      - Fri, 15 Sep 2023 05:36:58 GMT
      server:
      - uvicorn
    http_version: HTTP/1.1
    status_code: 200
- request:
    body: '{"prompt": ["Given a raw text input to a language model select the model
      prompt best suited for the input. You will be given the names of the available
      prompts and a description of what the prompt is best suited for. You may also
      revise the original input if you think that revising it will ultimately lead
      to a better response from the language model.\n\n<< FORMATTING >>\nReturn a
      markdown code snippet with a JSON object formatted to look like:\n```json\n{\n    \"destination\":
      string \\ name of the prompt to use or \"DEFAULT\"\n    \"next_inputs\": string
      \\ a potentially modified version of the original input\n}\n```\n\nREMEMBER:
      \"destination\" MUST be one of the candidate prompt names specified below OR
      it can be \"DEFAULT\" if the input is not well suited for any of the candidate
      prompts.\nREMEMBER: \"next_inputs\" can just be the original input if you don''t
      think any modifications are needed.\n\n<< CANDIDATE PROMPTS >>\nphysics: Good
      for answering questions about physics\nmath: Good for answering math questions\n\n<<
      INPUT >>\nWhat is black body radiation?\n\n<< OUTPUT (must include ```json at
      the start of the response) >>\n<< OUTPUT (must end with ```) >>\n"], "model":
      "text-davinci-003", "temperature": 0.7, "max_tokens": 256, "top_p": 1, "frequency_penalty":
      0, "presence_penalty": 0, "n": 1, "logit_bias": {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0xQO2/bMBDe/SsOnP1+JdVSdCjapmmnAi1aBRZFnq2zpTuCpNwIhv97QNlOsnC4
        783TAED9156JdyoD9auiAI1YrOGIPpAwUACLzqPREe0YftDO64hQ4lY8woPmVvsOlkOYT+dLiAL6
        KGTBUvCti8lBthDQH8ngGB5Re4YmSasYXcgmE1fruBXfjMUhaxobaSZWTJjcYkk4qGFqSjaVNI2r
        R3fdkfHT4utj933199ChtV++rT//KXG/e/h5YUu5RxOTIuJz3BhpXI3J7QIbj2mSymC2/rC8W63n
        s/se6PffZCOrj8SGRtPp4qqrhAwGlcG/AQDAqX/hQk+yoij2QTjnU84JyJXFEIn7JbnKIFeu6gKZ
        kKvhjcKpIrFrY7hQflc6ps8va20OUIrtwGtLvcnHXOV8zrkoir5TH09s8VllMH291LJzXspUldu6
        fr1viSlUG486CKfGIYpTPXoeADz1M9ugd6iy6zzlvDQubqIckJPh/P6ao97+9Q1drK5glKjrd/fZ
        apBCzoMXAAAA//8DAJNnkMp6AgAA
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e83e01d25ef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:36:59 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '862'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
- request:
    body: '{"prompt": ["You are a very smart physics professor. You are great at answering
      questions about physics in a concise and easy to understand manner. When you
      don''t know the answer to a question you admit that you don''t know.\n\nHere
      is a question:\nWhat is black body radiation?"], "model": "text-davinci-003",
      "temperature": 0.7, "max_tokens": 256, "top_p": 1, "frequency_penalty": 0, "presence_penalty":
      0, "n": 1, "logit_bias": {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA3RSy27cMAy871cQvvSSeB/NA9lb20tSpKfm1hQLWeLabCRRpWhv3CD/XsibzSaH
        XASIwxkONXqaAVQ7I5FiW62huusoQ2CHHgaUTByBMjhMgtYouhp+UCtGERrcsiB8N7E3MsLZCawW
        qzNQBjMwOXCUpU9aFHgLGWUgizXcopEIoVA71ZTX83nyRrcsoeaE0VBtOcwd2zw/jCWOuTopTskV
        kzYkf3o5DrG9uY7Bs/xcDWm8dV/ab/3u/Hp5/W/fzc0ftFoYio+6sRySx6K2h61gWalaw/Li6uzy
        /GK1WkzAtP+BdurMQNHS6WLx+YXXMVnM1Rp+zQAAnqYT9u2Fdh/v41dv7AM07EYQ42haojyldgjo
        0apwMG1EJfumAQOpooOtcAADzVGEYqFKYDdGE8gC/u3JUyPUhxpu9KAtmHuv5cnLbaIYDxhR2vFQ
        LYKfMiQjStZjhgYptmA5DihlPEXlj13WcNch5FTgPhxE323pUFECRXTQjHsnGBKK0V7wrY0T2JF2
        0FHbobxtypCEXW+LMQONsHEo74buzIAeY6tdrqdgpgwoOnys1rB4rXhuk3BT8oq996/1LUXK3UbQ
        ZI4ltqycqgl9ngH8nrLus2mxWr9kXCXhkHSj/ICxCJ5f7uWq4986gherF1BZjT/Wl8urWZnxPPsP
        AAD//wMAvM1fxH4DAAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e83e629abef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:37:01 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '1672'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
- request:
    body: '{"prompt": ["Given a raw text input to a language model select the model
      prompt best suited for the input. You will be given the names of the available
      prompts and a description of what the prompt is best suited for. You may also
      revise the original input if you think that revising it will ultimately lead
      to a better response from the language model.\n\n<< FORMATTING >>\nReturn a
      markdown code snippet with a JSON object formatted to look like:\n```json\n{\n    \"destination\":
      string \\ name of the prompt to use or \"DEFAULT\"\n    \"next_inputs\": string
      \\ a potentially modified version of the original input\n}\n```\n\nREMEMBER:
      \"destination\" MUST be one of the candidate prompt names specified below OR
      it can be \"DEFAULT\" if the input is not well suited for any of the candidate
      prompts.\nREMEMBER: \"next_inputs\" can just be the original input if you don''t
      think any modifications are needed.\n\n<< CANDIDATE PROMPTS >>\nphysics: Good
      for answering questions about physics\nmath: Good for answering math questions\n\n<<
      INPUT >>\nWhat is the first prime number greater than 40 such that one plus
      the prime number is divisible by 3\n\n<< OUTPUT (must include ```json at the
      start of the response) >>\n<< OUTPUT (must end with ```) >>\n"], "model": "text-davinci-003",
      "temperature": 0.7, "max_tokens": 256, "top_p": 1, "frequency_penalty": 0, "presence_penalty":
      0, "n": 1, "logit_bias": {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRy27bQAy8+yuIPfv9CqJLDwFaIEhzalG0VWCtJNpiKpGLXUq1Yfjfi5XsGL0s
        sBzOcIY8jwDMX+uZ+GASMN8qCtBIiTV06AMJAwUo0XksrGI5ha908FYRctyLR3i23Fp/gvUYlvPl
        GlTAdkIllBR86zQqyB4C+o4KnMILWs/QRGql6kIym7na6l58MxWHbGlaSDMrpQiz21gSDmYcnVIZ
        TRaNqycPp46r7SuVn4/bxffjz/Xzr9fmpfqyeOLt09At+TsWGhmKR90V0rgao9oAFx5jJJPAYvu4
        fthsl8tFD/T5b7RJaTvigibz+erKq4QKDCaB3yMAgHP/wtAeaVmWvQfhlM8pRyA1JQYl7pOkJoHU
        NFar1IxvOEd/xK7VMOA/Kqtx81oh7MkHBeepQeC2ydHDobfuQSvLsJ5DaIsqfhSEEVzdDsz/OPGO
        1FGgvEbIT7D6lJqULylnWdYH6zMQl3g0Ccw/KrUcnJc85uW2rj/qe2IK1c6jDcIxdlBxpkcvI4C3
        fldtsAc0yXVHxnlpnO5U/iBHweXjZtAz9+Pc0c3VhFFRW9/rq/VmFIdcRv8AAAD//wMA8f8eR78C
        AAA=
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e83f14907ef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:37:03 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '1605'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
- request:
    body: '{"prompt": ["You are a very good mathematician. You are great at answering
      math questions. You are so good because you are able to break down hard problems
      into their component parts, answer the component parts, and then put them together
      to answer the broader question.\n\nHere is a question:\nWhat is the first prime
      number greater than 40 such that one plus the prime number is divisible by 3?"],
      "model": "text-davinci-003", "temperature": 0.7, "max_tokens": 256, "top_p":
      1, "frequency_penalty": 0, "presence_penalty": 0, "n": 1, "logit_bias": {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA1RRy27bMBC86ysGPMe2Iitxo2OBAkUfQA+BL01hUNRKWlfiEiSlxg3y7wVlJ0Yv
        BDizszNDvmSA+qO9ZdupCuqx54BRGhowkw8sFhzQkPNkdKRmje/ceR0JNbXiCV+0nbQ/obxBkRcl
        okDPwg0aDn5yMW2QFoH8zIbW+EbaW4xJ2sfoQrXZuEHHVvy4FkdW89rIuGnEhM2bLYsN6iYl5SaF
        NKMbVrvTbI97s+9/fPj6+e7TXPDfj65sjrRv96fztNRHMjEpIj3Hg5HRDZS2nWnjKVVSFW7vH8rd
        3X1RbBdi6f8mWzV6Zmt4lefbi64XNhRUhZ8ZALwsJ87jSfZkn+xjT2jZhwjneSTYaazJo1s8PWKv
        LcocYTJ9ukSIJbhhCog9/a9JH8AzB64HQn3CNiHldr2kWYzZNvSsKuTvyCCd81KnkHYahne8Zcuh
        P3jSQWzKGqI4tbCvGfBrKTgF3ZGqLsWU8zK6eIjym2xauHs4r1PXB72SRXkho0Q9XPHbfJslj9fs
        HwAAAP//AwDoGMIAcwIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e83fbf81eef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:37:04 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '843'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
- request:
    body: '{"prompt": ["Given a raw text input to a language model select the model
      prompt best suited for the input. You will be given the names of the available
      prompts and a description of what the prompt is best suited for. You may also
      revise the original input if you think that revising it will ultimately lead
      to a better response from the language model.\n\n<< FORMATTING >>\nReturn a
      markdown code snippet with a JSON object formatted to look like:\n```json\n{\n    \"destination\":
      string \\ name of the prompt to use or \"DEFAULT\"\n    \"next_inputs\": string
      \\ a potentially modified version of the original input\n}\n```\n\nREMEMBER:
      \"destination\" MUST be one of the candidate prompt names specified below OR
      it can be \"DEFAULT\" if the input is not well suited for any of the candidate
      prompts.\nREMEMBER: \"next_inputs\" can just be the original input if you don''t
      think any modifications are needed.\n\n<< CANDIDATE PROMPTS >>\nphysics: Good
      for answering questions about physics\nmath: Good for answering math questions\n\n<<
      INPUT >>\nWhat is the name of the type of cloud that rins\n\n<< OUTPUT (must
      include ```json at the start of the response) >>\n<< OUTPUT (must end with ```)
      >>\n"], "model": "text-davinci-003", "temperature": 0.7, "max_tokens": 256,
      "top_p": 1, "frequency_penalty": 0, "presence_penalty": 0, "n": 1, "logit_bias":
      {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0RQS2/iMBC+8ytGPvMIKYVtLtW+V6vujVUPm4oYeyDTJjNe22FLEf995QDlYlnz
        Peb75jAAUP+0Z+KtKkAtawrQisUGdugDCQMFsOg8Gh3RjuEXbb2OCGvciEf4qbnTfg+zIeRZPoMo
        oHdCFiwF37mYHGQDAf2ODI7hAbVnaJO0jtGFYjJxjY4b8e1YHLKmsZF2YsWEyWUtCQc1TEnJppCm
        dc1osd/xy4/lss1uSehx+vltGj55+tstv9u7E1vWz2hiUkR8jSsjrWswuZ1g4zFVUgVM53ezxe08
        z2c90Pe/yEZW74gNjbLs5qyrhQwGVcCfAQDAoX/hRE+yqqqeg3DJh5ITUCqLIRL3TUpVQKm+fP32
        8ffDslTDC4VTRGLXxXCiPNY6puPHGoF1i+mM6R/3rv+bRjoLMbG8Jg73pSr5WHJVVX3OPhKxxVdV
        QPY+aWTrvKxTfO6a5n2+IaZQrzzqIJxahChO9ehxAPDUV++C3qIqzpWV89K6uIrygpwM8w/zk5+6
        3vqKzqZnMErUzXV+ky8Gaclx8B8AAP//AwCcwAHIjgIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e8401fbdbef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:37:05 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '1099'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
- request:
    body: '{"prompt": ["The following is a friendly conversation between a human and
      an AI. The AI is talkative and provides lots of specific details from its context.
      If the AI does not know the answer to a question, it truthfully says it does
      not know.\n\nCurrent conversation:\n\nHuman: What is the name of the type of
      cloud that rains?\nAI:"], "model": "text-davinci-003", "temperature": 0.7, "max_tokens":
      256, "top_p": 1, "frequency_penalty": 0, "presence_penalty": 0, "n": 1, "logit_bias":
      {}}'
    headers: {}
    method: POST
    uri: https://api.openai.com/v1/completions
  response:
    body:
      string: !!binary |
        H4sIAAAAAAAAA0xRy24bMQy8+ysGe+nFr7pujPoeFCnSQ4EU6AOFwZVoLxstKUjaTdyg/15onQS9
        6EDOjGaGTzOgeaCkoqdmj+auk4zePAeMnLKYQjI8x8SOCvslPsspUWG0fLTE+EQ6UDpjO8dmvdmi
        GGg08fCS0xBLVbAjMqdRHC9xy5QUfaV2pcS8X61ioHK01C8tspIsnfUrby6vXr4V09zMq1Px1aTr
        Y1jszqP21/72uzj348u3P8fhhtpw/VF2+rW9oK39za5URuHHcnDWx8BV7bJ2iWukZo+3Vx+2u/dX
        m83VtJjyv9AWnkZRJ4v1+t0zrzNxnJs9fs4A4Gl6cYFXGu46RjlHrsldsMGjdFSQSDTXPh2FwB4E
        N/RDMJW+HfIFucRNeZNBKBTCHJ7S/f8SkmHHwgpyNQ6psEd7RukG9ZxA6hHk1JV60Kp1+S5SGyY3
        MZkfnOgJHdN4nizN0ZGE+cTlkRVZ7aHenNVXpClKDcR95ERlSLycipgyi3p+bPZYv06CnWKytvaj
        Qwiv86Oo5O6QmLJprSkXi820/TsDfk3dDplO3OyfO21isj6WQ7F71n8CGWhuDDFOCRGXCElTqBuU
        SvJLEnMQ4oZGxlwgO2q5AAAAAP//AwD1dAMT7gIAAA==
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 806e84097929ef6f-PDX
      Cache-Control:
      - no-cache, must-revalidate
      Connection:
      - keep-alive
      Content-Encoding:
      - gzip
      Content-Type:
      - application/json
      Date:
      - Fri, 15 Sep 2023 05:37:07 GMT
      Transfer-Encoding:
      - chunked
      openai-model:
      - text-davinci-003
      openai-processing-ms:
      - '1547'
      x-ratelimit-limit-tokens_usage_based:
      - '250000'
      x-ratelimit-remaining-tokens_usage_based:
      - '249744'
      x-ratelimit-reset-tokens_usage_based:
      - 61ms
    status:
      code: 200
      message: OK
version: 1
